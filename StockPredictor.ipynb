{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports e funzione per prendere i dati degli stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import delle librerie necessarie\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lista dei ticker che vogliamo scaricare\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"TSLA\", \"AMZN\"]\n",
    "\n",
    "# Funzione per scaricare i dati di ciascun ticker e verificare la data di inizio\n",
    "def get_stock_data(ticker, start_date='2010-01-01', end_date=None):\n",
    "    if end_date is None:\n",
    "        end_date = pd.to_datetime(\"today\").strftime('%Y-%m-%d')\n",
    "\n",
    "    print(f\"\\nScaricando dati per {ticker} dal {start_date} al {end_date}...\")\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "    if data.empty:\n",
    "        print(f\"‚ö†Ô∏è Nessun dato disponibile per {ticker} nel periodo richiesto.\")\n",
    "    else:\n",
    "        first_date = data.index.min().strftime('%Y-%m-%d')\n",
    "        print(f\"üìà Dati disponibili dal {first_date}. Numero di record: {len(data)}\")\n",
    "\n",
    "    # Aggiungiamo il ticker come colonna\n",
    "    data['Ticker'] = ticker\n",
    "\n",
    "    data.columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Ticker']\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendiamo i dati per Google nel 2015 e analizziamoli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trova il primo mese disponibile\n",
    "first_month = ('2015')\n",
    "\n",
    "data = get_stock_data('GOOGL')\n",
    "\n",
    "# Filtra il dataset per il primo mese\n",
    "data_first_month = data.loc[first_month]\n",
    "data_first_month.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plottiamo il volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_first_month['Volume'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applichiamo la rolling window a tutti i campi e analizziamo le caratteristiche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riduzione del rumore tramite media mobile\n",
    "for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
    "        data_first_month[col] = data_first_month[col].rolling(window=10, min_periods=1).mean()\n",
    "\n",
    "data_first_month.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plottiamo il nuovo volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_first_month['Volume'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendiamo i dati per tutti gli stock e regoliamo il volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_list = []\n",
    "for ticker in tickers:\n",
    "    data = get_stock_data(ticker)\n",
    "    data['Volume'] = data['Volume'].rolling(window=10, min_periods=1).mean()\n",
    "    dataset_list.append(data)\n",
    "\n",
    "for i in range(len(dataset_list)):\n",
    "    dataset_list[i] = dataset_list[i].reset_index()  # Resetta l‚Äôindice\n",
    "    dataset_list[i]['Date'] = pd.to_datetime(dataset_list[i]['Date'])  # Assicura che Date sia un datetime\n",
    "    dataset_list[i] = dataset_list[i].set_index('Date')  # Imposta Date come indice\n",
    "\n",
    "all_data = pd.concat(dataset_list, axis=0, join='outer')  # Combina tutti i dataset\n",
    "all_data = all_data.sort_index()  # Ordina per data\n",
    "\n",
    "all_data.dropna(inplace=True)\n",
    "\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlliamo che non ci siano valori nulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se ci sono NaN nell'intero dataset\n",
    "has_nan = all_data.isna().any().any()\n",
    "\n",
    "if has_nan:\n",
    "    print(\"Ci sono valori NaN nel dataset.\")\n",
    "else:\n",
    "    print(\"Non ci sono valori NaN nel dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizziamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Seleziona solo le colonne numeriche da normalizzare\n",
    "columns_to_normalize = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "# Applica la normalizzazione separatamente per ogni ticker\n",
    "normalized_data_list = []\n",
    "for ticker in all_data['Ticker'].unique():\n",
    "    subset = all_data[all_data['Ticker'] == ticker].copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    subset[columns_to_normalize] = scaler.fit_transform(subset[columns_to_normalize])\n",
    "    normalized_data_list.append(subset)\n",
    "\n",
    "# Unisci di nuovo i dati normalizzati\n",
    "all_data_normalized = pd.concat(normalized_data_list)\n",
    "\n",
    "# Mostra i primi valori normalizzati\n",
    "all_data_normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisione in finestre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parametri\n",
    "window_size = 60  # Dimensione della finestra temporale\n",
    "forecast_horizon = 7  # Giorni futuri da prevedere\n",
    "feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume']  # Colonne di interesse\n",
    "\n",
    "# Funzione per creare finestre temporali con multi-step forecasting\n",
    "def create_time_windows_per_ticker(data, window_size, forecast_horizon):\n",
    "    X, y = [], []\n",
    "\n",
    "    tickers = data['Ticker'].unique()  # Trova i ticker unici\n",
    "    for ticker in tickers:\n",
    "        ticker_data = data[data['Ticker'] == ticker].reset_index(drop=True)\n",
    "\n",
    "        for i in range(window_size, len(ticker_data) - forecast_horizon):\n",
    "            # Finestra temporale di input\n",
    "            X.append(ticker_data[feature_columns].iloc[i-window_size:i].values)\n",
    "            # Prevedi i prossimi 'forecast_horizon' giorni di prezzo di chiusura\n",
    "            future_returns = ticker_data['Close'].iloc[i:i+forecast_horizon].values\n",
    "            y.append(future_returns)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Creazione delle finestre temporali\n",
    "X, y = create_time_windows_per_ticker(all_data_normalized, window_size, forecast_horizon)\n",
    "\n",
    "# Verifica delle dimensioni degli array risultanti\n",
    "print(f\"Dimensione di X: {X.shape}\")  # (n_finestre, 60, n_features)\n",
    "print(f\"Dimensione di y: {y.shape}\")  # (n_finestre, 30)\n",
    "\n",
    "# Visualizzazione di un esempio di finestra temporale\n",
    "print(\"Esempio di X:\", X[0])\n",
    "print(\"Esempio di y:\", y[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisione in training e test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suddividere i dati in training e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Istanziamo il modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "# Crea il modello LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=512, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))  # Dropout per evitare overfitting\n",
    "model.add(Dense(forecast_horizon))  # Layer finale per la previsione del valore 'Close'\n",
    "\n",
    "# Compilare il modello\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Riassunto del modello\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addestramento del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allenare il modello\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prevision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare previsioni sui dati di test\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Visualizzare i risultati\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(y_test[3700], label='True Values')\n",
    "plt.plot(predictions[3700], label='Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "print(f\"Shape of predictions: {predictions.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average comparison on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola la media lungo tutte le finestre temporali\n",
    "y_test_mean = np.mean(y_test, axis=0)\n",
    "predictions_mean = np.mean(predictions, axis=0)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_mean, label='True Values (Mean)', color='blue')\n",
    "plt.plot(predictions_mean, label='Predicted Values (Mean)', color='red', linestyle='dashed')\n",
    "plt.xlabel('Days in the Future')\n",
    "plt.ylabel('Close Price')\n",
    "plt.title('Average Prediction vs True Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficiency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Calcola MSE, MAE e R¬≤\n",
    "mse = mean_squared_error(y_test.flatten(), predictions.flatten())\n",
    "mae = mean_absolute_error(y_test.flatten(), predictions.flatten())\n",
    "r2 = r2_score(y_test.flatten(), predictions.flatten())\n",
    "\n",
    "# Mostra i risultati\n",
    "print(\"=== Valori di Controllo Qualit√† ===\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "\n",
    "# Visualizzazione delle differenze tra i valori reali e le previsioni\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test.flatten(), label=\"True Values\", alpha=0.6)\n",
    "plt.plot(predictions.flatten(), label=\"Predictions\", alpha=0.6)\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Close Price')\n",
    "plt.title('True Values vs Predictions')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to use the model to predict a stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictaa(name, a):\n",
    "    newdata = get_stock_data(name)\n",
    "    newdata['Volume'] = newdata['Volume'].rolling(window=10, min_periods=1).mean()\n",
    "\n",
    "    columns_to_normalize = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    newdata[columns_to_normalize] = scaler.fit_transform(newdata[columns_to_normalize])\n",
    "\n",
    "    X, y = create_time_windows_per_ticker(newdata, window_size, 7)\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    mse = mean_squared_error(y.flatten(), predictions.flatten())\n",
    "    mae = mean_absolute_error(y.flatten(), predictions.flatten())\n",
    "    r2 = r2_score(y.flatten(), predictions.flatten())\n",
    "\n",
    "    # Mostra i risultati\n",
    "    print(\"=== Valori di Controllo Qualit√† ===\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "\n",
    "    # Calcoliamo l'errore percentuale\n",
    "    percentage_change = np.abs((y.flatten() - predictions.flatten()) / y.flatten()) * 100\n",
    "\n",
    "    # Visualizziamo qualche statistica utile\n",
    "    mean_percentage_change = np.mean(percentage_change)\n",
    "    max_percentage_change = np.max(percentage_change)\n",
    "    min_percentage_change = np.min(percentage_change)\n",
    "\n",
    "    print(f\"Mean Percentage Change: {mean_percentage_change:.2f}%\")\n",
    "    print(f\"Max Percentage Change: {max_percentage_change:.2f}%\")\n",
    "    print(f\"Min Percentage Change: {min_percentage_change:.2f}%\")\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y[a], label='Valori reali')\n",
    "    plt.plot(predictions[a], label='Predizioni')\n",
    "    plt.legend()\n",
    "    plt.title('Confronto tra valori reali e predizioni per il nuovo stock')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(percentage_change, label='Percentage Change (%)', color='orange')\n",
    "    plt.axhline(y=mean_percentage_change, color='red', linestyle='--', label='Mean % Change')\n",
    "    plt.xlabel('Prediction Index')\n",
    "    plt.ylabel('Percentage Change (%)')\n",
    "    plt.legend()\n",
    "    plt.title('Percentage Change between True and Predicted Values')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Netflix Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictaa('NFLX', 150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
